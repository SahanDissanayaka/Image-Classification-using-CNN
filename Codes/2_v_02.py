# -*- coding: utf-8 -*-
"""2_v_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vrym8_XLwuR4DkJdJ7S9enHfjvO92hPK
"""

from google.colab import drive
drive.mount('/content/drive')

dataset_path = '/content/drive/MyDrive/realwaste/realwaste-main/RealWaste'

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

# Image data generators for training and validation
image_size = (224, 224)  # ResNet input size
batch_size = 32

# Training data generator
train_datagen = ImageDataGenerator(
    rescale=1.0/255,               # Normalize pixel values
    rotation_range=20,             # Randomly rotate images
    width_shift_range=0.2,         # Randomly shift images horizontally
    height_shift_range=0.2,        # Randomly shift images vertically
    shear_range=0.2,               # Randomly shear images
    zoom_range=0.2,                # Randomly zoom in on images
    horizontal_flip=True,          # Randomly flip images horizontally
    validation_split=0.2           # Reserve 20% for validation
)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Load the pretrained ResNet50 model
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
base_model.trainable = False

# Add custom classification head
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer matches number of classes
])

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model
epochs = 10
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=epochs
)

# Optionally, unfreeze the base model for fine-tuning
base_model.trainable = True
fine_tune_at = len(base_model.layers) - 50  # Unfreeze last 50 layers

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fine-tune the model
fine_tune_epochs = 5
total_epochs = epochs + fine_tune_epochs

history_fine = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=total_epochs,
    initial_epoch=history.epoch[-1]
)

# # Save the model
# model.save('resnet_trained_model.h5')

